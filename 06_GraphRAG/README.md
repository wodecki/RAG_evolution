# GraphRAG vs Naive RAG: CV Knowledge Graph Comparison

A comprehensive demonstration of **GraphRAG vs Naive RAG** using realistic PDF CVs and LLM-powered knowledge graph extraction. This project showcases how knowledge graphs enable structured queries that are impossible with traditional vector-based RAG systems.

## ğŸš€ Quick Start

### Prerequisites
- **Python 3.11+** with `uv` package manager
- **Docker Desktop** (for Neo4j database)
- **OpenAI API Key** (set in `.env` file)

### One-Command Demo
```bash
# Complete end-to-end comparison
uv run python 5_compare_systems.py
```

### Step-by-Step Workflow
```bash
# 1. Initial setup and validation
uv run python 0_setup.py

# 2. Start Neo4j database
./start_session.sh

# 3. Generate 30 realistic CV PDFs
uv run python 1_generate_data.py

# 4. Extract knowledge graph from CVs using LLMGraphTransformer
uv run python 2_data_to_knowledge_graph.py

# 5. Run complete comparison
uv run python 5_compare_systems.py
```

## ğŸ¯ Problem Addressed

Traditional RAG systems struggle with structured queries requiring:

| Query Type | Example | Traditional RAG Issue |
|------------|---------|---------------------|
| **Counting** | "How many Python developers?" | âŒ Estimates from text chunks |
| **Filtering** | "Find people with Docker AND Kubernetes" | âŒ Limited to semantic similarity |
| **Aggregation** | "Average years of experience?" | âŒ Cannot calculate across entities |
| **Sorting** | "Top 3 most experienced developers" | âŒ No structured ranking |
| **Multi-hop** | "People who attended same university" | âŒ Cannot traverse relationships |

## ğŸ—ï¸ Architecture

### Knowledge Graph Schema
**Auto-extracted from PDF CVs using LLMGraphTransformer:**

```
Nodes:
â”œâ”€â”€ Person (id, name, location, bio)
â”œâ”€â”€ Skill (id, category)
â”œâ”€â”€ Company (id, industry, location)
â”œâ”€â”€ University (id, location, type)
â””â”€â”€ Certification (id, provider, field)

Relationships:
â”œâ”€â”€ (Person)-[HAS_SKILL]->(Skill)
â”œâ”€â”€ (Person)-[WORKED_AT]->(Company)
â”œâ”€â”€ (Person)-[STUDIED_AT]->(University)
â”œâ”€â”€ (Person)-[EARNED]->(Certification)
â””â”€â”€ (Person)-[MENTIONS]->(Person)
```

### System Components
- **PDF Processing**: Realistic CV generation with reportlab
- **Knowledge Extraction**: LangChain LLMGraphTransformer
- **Graph Database**: Neo4j with Docker
- **GraphRAG**: LangChain GraphCypherQAChain with custom prompts
- **Naive RAG**: ChromaDB vector search baseline
- **Evaluation**: GPT-5 ground truth generation

## ğŸ“Š Example Results

### Query: "How many people have Python programming skills?"

**GraphRAG (âœ… Accurate):**
```cypher
MATCH (p:Person)-[:HAS_SKILL]->(s:Skill)
WHERE toLower(s.id) = toLower("Python")
RETURN count(p) AS pythonProgrammers
```
*Result: **7 people** (exact count)*

**Naive RAG (âŒ Incomplete):**
*Result: "Based on context, only **Amanda Smith** is mentioned" (missed 6 people)*

### Query: "List people with both React and Node.js skills"

**GraphRAG (âœ… Complete):**
*Result: **4 people** - Christine Rodriguez, Joseph Fuller, Krystal Castillo, William Bonilla*

**Naive RAG (âŒ Limited):**
*Result: **1 person** - Christine Rodriguez (missed 3 people)*

## ğŸ“ Project Structure

```
06_GraphRAG/
â”œâ”€â”€ 0_setup.py                 # Environment validation
â”œâ”€â”€ 1_generate_data.py          # Synthetic PDF CV generation
â”œâ”€â”€ 2_data_to_knowledge_graph.py  # LLM graph extraction
â”œâ”€â”€ 3_query_knowledge_graph.py  # GraphRAG implementation
â”œâ”€â”€ 4_naive_rag_cv.py          # Naive RAG baseline
â”œâ”€â”€ 5_compare_systems.py       # System comparison
â”œâ”€â”€ docker-compose.yml         # Neo4j setup
â”œâ”€â”€ start_session.sh           # Neo4j management
â”œâ”€â”€ utils/                     # Utility files
â”‚   â”œâ”€â”€ generate_ground_truth.py  # GPT-5 ground truth
â”‚   â”œâ”€â”€ test_questions.json    # Evaluation questions
â”‚   â””â”€â”€ config.toml           # Configuration
â”œâ”€â”€ data/programmers/          # Generated CV PDFs
â””â”€â”€ results/                   # Comparison results
    â”œâ”€â”€ ground_truth_answers.json
    â””â”€â”€ comparison_report.md
```

## ğŸ”§ Technical Stack

- **Language**: Python 3.11+
- **Package Manager**: uv
- **LLM**: OpenAI GPT-4o (queries), GPT-5 (ground truth)
- **Graph Database**: Neo4j 5.x with Docker
- **Vector Store**: ChromaDB (baseline comparison)
- **Frameworks**: LangChain, LangChain Experimental
- **Document Processing**: Unstructured, ReportLab

## ğŸ“ Key Learnings

1. **GraphRAG excels** at structured queries requiring precise relationships
2. **LLMGraphTransformer** enables real-world PDF-to-knowledge-graph workflows
3. **Custom Cypher prompts** solve case sensitivity and result interpretation issues
4. **GPT-5 ground truth** provides unbiased evaluation
5. **Hybrid approaches** can combine both strengths for optimal results


## ğŸ” Advanced Usage

### Browse Knowledge Graph
Neo4j Browser: http://localhost:7474 (neo4j/password123)

### Individual Components
```bash
# Test GraphRAG only
uv run python 3_query_knowledge_graph.py

# Test Naive RAG only
uv run python 4_naive_rag_cv.py

# Generate ground truth only
uv run python utils/generate_ground_truth.py
```

## ğŸ¤ Real-World Applications

This approach applies to any domain with:
- **Structured relationships** between entities
- **Precise counting/filtering** requirements
- **Multi-hop reasoning** needs
- **Complex business queries**

Examples: Staffing, inventory management, medical records, financial risk analysis.

---

**ğŸ‰ Success!** You've demonstrated the clear advantages of GraphRAG for structured business queries while maintaining natural language accessibility.